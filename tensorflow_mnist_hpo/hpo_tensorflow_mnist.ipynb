{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Tensorflow Containerを使用したハイパーパラメータチューニング\n",
    "\n",
    "このチュートリアルでは、**SageMaker TensorFlowコンテナ** を使用して[MNISTデータセット](http://yann.lecun.com/exdb/mnist/) をトレーニングするための畳み込みニューラルネットワークモデルを作成する方法に焦点を当てています。 ハイパーパラメータチューニングを活用して、さまざまなハイパーパラメータの組み合わせを使用して複数のトレーニングジョブを開始し、最良のモデルトレーニング結果を持つトレーニングを見つけます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境を設定する\n",
    "ワークフローを開始する前に環境を設定します。\n",
    "\n",
    "1. トレーニングデータセットとモデル成果物が格納されるS3バケットとプレフィックスを指定する。\n",
    "1. SageMakerに渡される実行ロールを取得して、S3バケットなどのリソースにアクセスします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket() # we are using a default bucket here but you can change it to any bucket in your account\n",
    "prefix = 'sagemaker/DEMO-hpo-tensorflow-high' # you can customize the prefix (subfolder) here\n",
    "\n",
    "role = sagemaker.get_execution_role() # we are using the notebook instance role for training in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、必要なPythonライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000)\n",
    "\n",
    "utils.convert_to(data_sets.train, 'train', 'data')\n",
    "utils.convert_to(data_sets.validation, 'validation', 'data')\n",
    "utils.convert_to(data_sets.test, 'test', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データをアップロードする\n",
    "私たちは ```sagemaker.Session.upload_data``` 関数を使ってデータセットをS3の場所にアップロードします。 戻り値の`input`は、トレーニングジョブの開始時に使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker.Session().upload_data(path='data', bucket=bucket, key_prefix=prefix+'/data/mnist')\n",
    "print (inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分散学習用のスクリプトを作成する\n",
    "ネットワークモデルの完全なコードは次のとおりです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pygmentize 'mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "このスクリプトは、[TensorFlow MNIST example](https://github.com/tensorflow/models/tree/master/official/mnist) の拡張です。これは、`model_fn(features, labels, mode)` を提供し、学習、評価、推論に使用されます。\n",
    "\n",
    "### 通常の ```model_fn```\n",
    "\n",
    "通常の**``` model_fn```**は、下記のような流れになります。\n",
    "1. [ニューラルネットワークを定義する](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L96)\n",
    " -  [ニューラルネットワークで ```features```を適用する。](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L178)\n",
    " -  [``mode``が ``PREDICT``であれば、ニューラルネットワークの出力を返す。](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py＃L186)\n",
    " -  [出力を ``labels``と比較する損失関数を計算する](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L188)\n",
    " -  [オプティマイザを作成し、損失関数を最小化し、ニューラルネットワークを改善する。](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L193)\n",
    " -  [出力、オプティマイザ、損失関数を返す。](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L205)\n",
    "\n",
    "### 分散学習のための ```model_fn```を書く\n",
    "分散トレーニングが行われると、複数のトレーニングインスタンスに同じニューラルネットワークが送信されます。各インスタンスは、データセットのバッチを予測し、損失を計算し、オプティマイザを最小化します。このプロセスのループ全体を **トレーニングステップ** と呼びます。\n",
    "\n",
    "### 同期トレーニングのステップ\n",
    "[グローバルステップ](https://www.tensorflow.org/api_docs/python/tf/train/global_step)は、インスタンス間で共有されるグローバル変数です。分散学習では、オプティマイザは実行間の **トレーニングステップ** の数を追跡する必要があります。\n",
    "\n",
    "```python\n",
    "train_op = optimizer.minimize（loss、tf.train.get_or_create_global_step（））\n",
    "```\n",
    "分散学習のために必要な変更は、たったこれだけです！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータチューニングジョブを設定する\n",
    "*以下のデフォルト設定では、ハイパーパラメータチューニングジョブは完了するまでに約30分かかります。\n",
    "\n",
    "ここで、SageMaker Python SDKを使用して、以下の手順に従って、ハイパーパラメータチューニングジョブを設定します。\n",
    "* TensorFlowトレーニングジョブを設定する``estimator``を作成します。\n",
    "* チューニングする予定のハイパーパラメータの範囲を定義します。この例では、 ```learning_rate```を調整しています。\n",
    "* 最適化するチューニングジョブの客観的なメトリックを定義します。\n",
    "* 上記の設定でハイパーパラメータチューナーを作成し、リソース設定を調整します。\n",
    "* ```batch_size```など、別のハイパーパラメータも同時に最適化にかけられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMakerで単一のTensorFlowジョブを習得するのと同様に、TensorFlowスクリプト、IAMロール、および（ジョブごとの）インスタンス構成を渡すTensorFlow estimatorを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point='mnist.py',\n",
    "                  role=role,\n",
    "                  framework_version='1.11.0',\n",
    "                  training_steps=1000, \n",
    "                  evaluation_steps=100,\n",
    "                  train_instance_count=4,\n",
    "#                  train_instance_type='ml.m4.xlarge',\n",
    "                  train_instance_type='ml.c5.2xlarge',\n",
    "                  base_job_name='DEMO-hpo-tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estimator`を定義したら、調整したいハイパーパラメーターとその可能な値を指定できます。 我々は、3つの異なるタイプのハイパーパラメータを有する。\n",
    " - カテゴリカルパラメータは、離散集合から1つの値を取る必要があります。 これを定義するには、可能な値のリストを `CategoricalParameter（list）`に渡します。\n",
    " - 連続パラメータは、 `ContinuousParameter（min、max）`で定義される最小値と最大値の間の任意の実数値をとることができます。\n",
    " - 整数パラメータは、IntegerParameter（min、max）で定義される最小値と最大値の間の任意の整数値をとることができます。\n",
    "\n",
    "*可能であれば、最も制限の少ないタイプとして値を指定することがほとんど常にベストであることに注意してください。 たとえば、学習率を0.01と0.2の間の連続値として調整すると、0.01、0.1、0.15、または0.2の値を持つカテゴリパラメータとしてチューニングするよりも良い結果が得られる可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.01, 0.2)}\n",
    "#hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.01, 0.2), 'batch_size':CategoricalParameter([50, 100, 200])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimatorを定義したら、調整したいハイパーパラメーターとその可能な値を指定できます。ここでは、3つの異なるタイプのハイパーパラメーターを定義できます。\n",
    "  * カテゴリカルパラメータは、離散集合から1つの値を取る必要があります。これを定義するには、可能な値のリストを `CategoricalParameter（list）`に渡します。\n",
    "  * 連続パラメタは、 `ContinuousParameter（min、max）`で定義される最小値と最大値の間の任意の実数値をとることができます。\n",
    "  * 整数パラメータは、`IntegerParameter（min、max）`で定義される最小値と最大値の間の任意の値をとることができます。\n",
    "\n",
    "*可能であれば、できるだけ限られた適切な範囲で値を指定することで、より良い解が得られること注意してください。学習率を0.01と0.2の間の連続値として調整すると、0.01,0.1 、0.15、または0.2の値を持つカテゴリパラメタとしてチューニングするより良い結果が得られる可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'loss'\n",
    "objective_type = 'Minimize'\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': 'loss = ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、`HyperparameterTuner`オブジェクトを作成します。\n",
    "* 上記で作成したTensorFlow estimator\n",
    "* ハイパーパラメータの範囲\n",
    "* ターゲットメトリクス定義\n",
    "* 合計で実行するトレーニング・ジョブの数、並行して実行できるトレーニング・ジョブの数などのリソース構成をチューニングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "        　                    hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=9,\n",
    "                            max_parallel_jobs=3,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータチューニングジョブを起動する\n",
    "最後に、 `.fit（）`を呼び出してS3パスをtrainとtest datasetに渡すことで、ハイパープレーターチューニングジョブを開始することができます。\n",
    "\n",
    "ハイパーパラメータチューニングジョブが作成されたら、次のステップでチューニングジョブの進捗状況を表示できるようになり、SageMakerのコンソール - >ジョブに移動して、ハイパーパラメータチューニングジョブの進行状況を確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハイパーパラメータ調整ジョブの状態を素早くチェックして、正常に起動したことを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チューニングジョブの結果を分析する - チューニングジョブが完了した後\n",
    "チューニングジョブの結果を分析するためのサンプルコードについては、```HPO_Analyze_TuningJob_Results.ipynb```を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベストモデルを展開する\n",
    "最良のモデルを得たので、これをエンドポイントに導入することができます。 モデルを展開する方法については、他のSageMakerサンプルノートブックまたはSageMakerのマニュアルを参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
